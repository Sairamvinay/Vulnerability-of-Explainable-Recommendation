from __future__ import print_function
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow.python import pywrap_tensorflow
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import random
import numpy as np
import glob
import sklearn
import math
import argparse
import sys
from pathlib import Path
import pickle
sys.path.append("../../data")
from text_processed_dataset import TextProcessedDataset
from yelp_processed_dataset import YelpProcessedDataset
from util_a2cf import plot_metrics
os.environ['CUDA_VISIBLE_DEVICES'] = '2'



print("TF version:",tf.__version__)

def args_process():    # Parse argument
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", dest="dataset", type=str, default="electronics",help = 'Name of the dataset')
    parser.add_argument("--adv", dest="adv", type=bool, default = False, help="whether to do adversarial or not")
    parser.add_argument("--adv_method", dest="adv_method", type=str, default = 'FGSM', help="whether to do which adversarial method? Random or FGSM")
    parser.add_argument("--print_every",dest = "print_every",type = int, default = 10, help = 'print every x batches once')
    parser.add_argument("--neg_size", type = int, default = 2, help = 'Negative samples per one positive sample')
    parser.add_argument("--dim", type = int, default = 64, help = 'Hidden Embedding dimensions')
    parser.add_argument("--eps", dest="eps", type=float, default=0.5, help="Error proportion for adversarial training")
    parser.add_argument("--dropout", dest="dropout", type=float, default=0.4, help="Dropout for learning")
    parser.add_argument("--lr", dest="lr", type=float, default=0.001, help="learning rate for training")
    parser.add_argument("--seed", dest="seed", type=int, default=999, help="seed for training")
    parser.add_argument("--epochs", dest="epochs", type=int, default=100, help="training epoch")
    parser.add_argument("--rc_epochs", dest="rc_epochs", type=int, default=2, help="training epoch for reconstruction")
    parser.add_argument("--rank_epochs", dest="rank_epochs", type=int, default=1, help="training epoch for recommendation")
    parser.add_argument("--batch_size", dest="batch_size", type=int, default=256, help="batch size for training base rec model")
    parser.add_argument("--verbose", type = int, default = 0, help = 'Print extra info')
    parser.add_argument("--data_path",dest = 'data_path', type=str, default ='../data/final-obj/Electronics_dataset_obj.pickle',help = "Path to the dataset for loading")
    parser.add_argument("--rec_k", dest="rec_k", type=int, default=5, help="length of rec list")
    parser.add_argument("--model_path", dest="model_path", type=str, default="./logs/",help = 'path to vanilla model')
    args = parser.parse_args()
    return args



def print_gradients_rec(p_loss,q_loss,sess,params,feed_dict):
    print("GRADIENTS for Train operation 1: UA Reconstruction")
    var_grad = tf.gradients(p_loss, [params['user_noise_embedding'], params['attribute_noise_embedding']])
    var_grad_val = sess.run(var_grad,feed_dict = feed_dict)
    for grad,var in zip(var_grad_val,['U','A']):
        print("VAR:",var,  ' \nGRAD:',grad.values, ' \n and its shape:',grad.values.shape)


    print("GRADIENTS for Train operation 1: IA Reconstruction")
    var_grad2 = tf.gradients(q_loss, [params['item_noise_embedding'], params['attribute_noise_embedding']])
    var_grad_val2 = sess.run(var_grad2,feed_dict = feed_dict)
    for grad,var in zip(var_grad_val2,['I','A']):
        print("VAR:",var,  ' \nGRAD:',grad.values, ' \n and its shape:',grad.values.shape)    
    
    return

def print_gradients_rank(BPR_loss,sess,params, feed_dict):
    print("GRADIENTS for Train operation 2: Recommendation")
    var_grad3 = tf.gradients(BPR_loss, [params['user_noise_embedding'],params['item_noise_embedding'],params['attribute_noise_embedding'],params["p_noise_projection_weight"]])
    var_grad_val3 = sess.run(var_grad3,feed_dict = feed_dict)
    for grad,var in zip(var_grad_val3,['U','I','A','Weight of projection in RS']):
        if var not in ['U','I']:
            print("VAR:",var,  ' \nGRAD:',grad, ' \n and its shape:',grad.shape)
        else:
            print("VAR:",var,  ' \nGRAD:',grad.values, ' \n and its shape:',grad.values.shape)
    
    return

def assign_noise_parameters(params, eps,adv = False):
    ops = []
    for variable in tf.global_variables():
        if 'noise' in variable.name:
            variable_parameters = 1 
            shape__ = variable.get_shape()
            shape__ = tuple(shape__)
            noise = tf.truncated_normal(shape=[shape__[0].value,shape__[1].value], mean=0.0, stddev=1)
            final_noise = tf.nn.l2_normalize(noise,1) * eps
            ops.append(variable.assign(final_noise))
    
    return ops

def assign_gradnoise_parameters(loss,weights, eps):
    ops = []
    gradients = tf.gradients(loss, weights)
    for i in range(len(weights)):
        variable = weights[i]
        grad_w = tf.stop_gradient(gradients[i])        
        final_grad = tf.nn.l2_normalize(grad_w,1)
        final_noise = final_grad * eps
        ops.append(variable.assign(final_noise))
        
    
    return ops


def print_total_parameters(params, adv = False):
    total_parameters = 0 
    
    if not adv:
        for variable in tf.trainable_variables():
            # shape is an array of tf.Dimension
            shape = variable.get_shape()
            variable_parameters = 1 
            for dim in shape:
                variable_parameters *= dim.value
            print('%s  dim=%i shape=%s params=%i' % ( 
                        variable.name,
                        len(shape),
                        shape,
                        variable_parameters,
                        ))  
            print("Variable value:",variable.eval())
            total_parameters += variable_parameters
        print('total_parameters = %i' % (total_parameters))

        print("-> NOISE PARAMS:")
        for n in tf.global_variables():
            if 'noise' in n.name:
                variable_parameters = 1 
                shape = n.get_shape()
                for dim in shape:
                    variable_parameters *= dim.value
                print(n.name, ' dim:',len(shape), ' shape:',shape, ' params:',variable_parameters,' value: ',n.eval())
    
    else:
        for param in params:
            variable = params[param]
            variable_parameters = 1 
            shape = variable.get_shape()
            for dim in shape:
                variable_parameters *= dim.value
            print(variable.name, 'is trainable:',variable.trainable, " dim:",len(shape), " params:", variable_parameters,' value:',variable.eval())
    
    
    return

##############
#data handler#
##############
class DataHandler(object):

    def __init__(self, rec_dataset,neg_size = 2):
        '''
        initialize all data
        '''
        self.data_interaction = []
        self.data_UACF = []
        self.data_IACF = []
        self.neg_num = 0
        
        print("-> loading interaction data now...")

        '''
        feature format: 
        [user (int), item_query (int), item_real (int), item_neg (int) x n]
        '''
        user_num = rec_dataset.user_num
        item_num = rec_dataset.item_num
        feature_num = rec_dataset.feature_num
        train_data = rec_dataset.training_data
        pos_user_data = {}
        neg_user_data = {}
        
        for row in train_data:
            
            user = row[0]
            item = row[1]
            label = row[2]
            if user not in pos_user_data:
                pos_user_data[user] = []
            
            if user not in neg_user_data:
                neg_user_data[user] = []
            
            if label == 1:
                pos_user_data[user].append(item)
            
            else:
                neg_user_data[user].append(item)
            
        
        total_users = 0
        for user in range(user_num):
            pos_items = pos_user_data[user]
            neg_items = neg_user_data[user]
            if len(neg_items) < neg_size:
                continue
            total_users += 1
            for pos_item in pos_items:
                curr_negs = np.random.choice(neg_items, neg_size, replace=False)
                curr_negs = curr_negs.tolist()
                self.data_interaction.append([user,pos_item, pos_item] + curr_negs) # for now i set query item same as current pos item but i set gamma to 0 for cancelling the item similarity
            
        
        
        
        
        random.shuffle(self.data_interaction)
        self.neg_num = len(self.data_interaction[0][3:])
        
        print("-> loading UACF data now...")
        
        '''
            feature format:
            [user (int), attribute (int), score (float)]
        '''
    
        
        for user in range(user_num):
            for feature in range(feature_num):
                val = rec_dataset.user_feature_matrix[user][feature]
                if val > 0:
                    self.data_UACF.append([int(user), int(feature), val])
        
    
        
        random.shuffle(self.data_UACF)

        print("-> loading IACF data now...")

        '''
                feature format:
                [item (int), attribute (int), score (float)]
        '''
        for item in range(item_num):
            for feature in range(feature_num):
                val = rec_dataset.item_feature_matrix[item][feature]
                if val > 0:
                    self.data_IACF.append([int(item), int(feature), val])
        
        random.shuffle(self.data_IACF)
        
        print("Details about training data:")
        print("Length of samples for UACF:",len(self.data_UACF))
        print("Length of samples for IACF:",len(self.data_IACF))
        print("Length of samples for A2CF:",len(self.data_interaction))
        print("All extracted users count:",total_users)
        self.batch_id = {"A2CF": 0, "UACF": 0, "IACF": 0}
        self.epoch_train = {"A2CF": 0, "UACF": 0, "IACF": 0}
        print("-> all data loaded.")

    def next(self, mode, batch_size):
        '''
        Return a batch of data. When dataset end is reached, start over.
        '''
        data_list = []
        if mode == "A2CF":
            data_list = self.data_interaction
        elif mode == "UACF":
            data_list = self.data_UACF
        elif mode == "IACF":
            data_list = self.data_IACF
        else:
            print("-> wrong mode flag used. use A2CF, UACF, or IACF.")

        if self.batch_id[mode] == len(data_list):
            self.batch_id[mode] = 0
            self.epoch_train[mode] += 1

        batch_feature = data_list[self.batch_id[mode]:min(self.batch_id[mode] + batch_size, len(data_list))]
        batch_first_section = []
        batch_second_section = []
        batch_third_section = []

        if mode == "UACF" or mode == "IACF":
            batch_first_section = [[line[0]] for line in batch_feature] # user (int) or item (int) in any case
            batch_second_section = [[line[1]] for line in batch_feature] # attribute (int)
            batch_third_section = [[x for x in line[2:]] for line in batch_feature] # score (float)
        else:
            for each_line in batch_feature:
                batch_first_section = batch_first_section + [[each_line[0]] for x in range(self.neg_num + 1)] # user (int)
                batch_second_section = batch_second_section + [[each_line[1]] for x in range(self.neg_num + 1)] # query item (int)
                batch_third_section = batch_third_section + [[x] for x in each_line[2:]] # real item (int) + neg items (int)

        self.batch_id[mode] = min(self.batch_id[mode] + batch_size, len(data_list))
        return batch_first_section, batch_second_section, batch_third_section

'''
network parameters
'''
args = args_process()
with open(args.data_path, 'rb') as handle:
    rec_dataset = pickle.load(handle)

print("DATASET:",args.dataset.upper())
rec_dataset.printDetails()

user_dim = rec_dataset.user_num
item_dim = rec_dataset.item_num
attribute_dim = rec_dataset.feature_num

neg_size = int(args.neg_size)

N = 5 # maximum score
batch_size = int(args.batch_size)
hidden_dim = int(args.dim)
beta = 8
epsilon = 8
gamma = 0 # so that we remove item similarity conditions #0.7 # 0<gamma<1
seed = int(args.seed)
adv = bool(args.adv)
adv_method = str(args.adv_method)
eps = float(args.eps)

random.seed(seed)
np.random.seed(seed)
tf.set_random_seed(seed)

dropout_keep_prob_train = float(args.dropout)
step_size = float(args.lr)

T_epoch1 = int(args.rc_epochs)
T_epoch2 = int(args.rank_epochs)

print("ARGS:",args)

'''
load and split data
'''
data_handler = DataHandler(rec_dataset, neg_size = neg_size)

print("-> loading the tf graph now...")

'''
running parameters
'''
display_step = int(args.print_every)
max_step = int(args.epochs)

'''
tf graph input
'''
u_query = tf.placeholder("int32", [None, 1]) #(batch, 1)
v_query = tf.placeholder("int32", [None, 1]) #(batch, 1)
v_candidate = tf.placeholder("int32", [None, 1]) #(batch, 1)
u_UACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
a_UACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
p_real = tf.placeholder("float", [None, 1]) #(batch, 1)
v_IACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
a_IACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
q_real = tf.placeholder("float", [None, 1]) #(batch, 1)

dropout_keep_prob = tf.placeholder("float")

'''
define parameters (weights & biases)
'''
params = {
    #____ embedding weights ____
    "user_embedding": tf.get_variable("user_embedding", shape = [user_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    "item_embedding": tf.get_variable("item_embedding", shape = [item_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    "attribute_embedding": tf.get_variable("helpful_embedding", shape = [attribute_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    #____ noise weights _____
    "user_noise_embedding": tf.get_variable("user_noise_embedding", shape = [user_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "item_noise_embedding": tf.get_variable("item_noise_embedding", shape = [item_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "attribute_noise_embedding": tf.get_variable("helpful_noise_embedding", shape = [attribute_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "p_noise_projection_weight": tf.get_variable("p_noise_projection_weight", shape = [2*hidden_dim, 1], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    
    #____ MF weights ____    
    "s_projection_weight": tf.get_variable("s_projection_weight", shape = [2*hidden_dim, 1], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    "p_projection_weight": tf.get_variable("p_projection_weight", shape = [2*hidden_dim, 1], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer)}

with tf.device("/CPU:0"):    
    params["P"] = tf.get_variable("P", trainable = False, initializer = tf.zeros([user_dim, attribute_dim]), caching_device = "/CPU:0")
    params["Q"] = tf.get_variable("Q", trainable = False, initializer = tf.zeros([item_dim, attribute_dim]), caching_device = "/CPU:0")
    

####################
####### A2CF #######
####################
def UACF(params, u_UACF, a_UACF, p_real, dropout_keep_prob):
    '''
    embedding layer
    '''
    u_emb = tf.nn.embedding_lookup(params["user_embedding"], u_UACF) #(batch, 1, hidden)
    u_emb = tf.reshape(u_emb, [-1, hidden_dim]) #(batch, hidden)
    
    u_emb_noise = tf.nn.embedding_lookup(params["user_noise_embedding"], u_UACF) #(batch, 1, hidden)
    u_emb_noise = tf.reshape(u_emb_noise, [-1, hidden_dim]) #(batch, hidden)
    
    u_emb_final = u_emb + u_emb_noise
    if a_UACF != None:
        a_emb = tf.nn.embedding_lookup(params["attribute_embedding"], a_UACF) #(batch, 1, hidden)
        a_emb = tf.reshape(a_emb, [-1, hidden_dim]) #(batch, hidden)
        a_emb_noise = tf.nn.embedding_lookup(params["attribute_noise_embedding"], a_UACF) #(batch, 1, hidden)
        a_emb_noise = tf.reshape(a_emb_noise, [-1, hidden_dim]) #(batch, hidden)
        a_emb_final = a_emb + a_emb_noise
    else:
        a_emb_final = params["attribute_embedding"] + params["attribute_noise_embedding"]
    
    '''
    dropout for embedding layer
    '''
    u_emb_final = tf.nn.dropout(u_emb_final, dropout_keep_prob)
    a_emb_final = tf.nn.dropout(a_emb_final, dropout_keep_prob)

    '''
    residual FFN layer
    '''
    h_0 = tf.concat([u_emb_final, a_emb_final], 1) # (batch, 2*hidden)
    h_1 = tf.layers.dense(tf.contrib.layers.layer_norm(h_0, begin_norm_axis = 1, begin_params_axis = -1), units = 2*hidden_dim, activation = tf.nn.relu, use_bias=True) #(batch, hidden)    
    h_1 = tf.add(h_0, tf.nn.dropout(h_1, dropout_keep_prob)) #(batch, hidden)

    '''
    prediction layer
    '''
    p_pred = tf.layers.dense(tf.contrib.layers.layer_norm(h_1, begin_norm_axis = 1, begin_params_axis = -1), units = 1, activation = tf.nn.tanh, use_bias=True) #(batch, 1)
    p_pred = (0.5*N - 0.5)*p_pred + 0.5*N + 0.5 #rescaled tanh

    '''
    summarizing batch loss
    '''
    this_batch_size = tf.cast(tf.shape(p_pred)[0], tf.float32)
    if p_real != None:
        loss = tf.reduce_sum(tf.square(tf.subtract(p_real, p_pred)))/this_batch_size
        loss = loss*batch_size
    else:
        loss = None

    return p_pred, loss

def IACF(params, v_IACF, a_IACF, q_real, dropout_keep_prob):
    '''
    embedding layer
    '''
    v_emb = tf.nn.embedding_lookup(params["item_embedding"], v_IACF)
    v_emb = tf.reshape(v_emb, [-1, hidden_dim]) #(batch, hidden)
    
    v_emb_noise = tf.nn.embedding_lookup(params["item_noise_embedding"], v_IACF)
    v_emb_noise = tf.reshape(v_emb_noise, [-1, hidden_dim]) #(batch, hidden)
    v_emb_final = v_emb + v_emb_noise
    
    if a_IACF != None:
        a_emb = tf.nn.embedding_lookup(params["attribute_embedding"], a_IACF)
        a_emb = tf.reshape(a_emb, [-1, hidden_dim]) #(batch, hidden)
        a_emb_noise = tf.nn.embedding_lookup(params["attribute_noise_embedding"], a_IACF) #(batch, 1, hidden)
        a_emb_noise = tf.reshape(a_emb_noise, [-1, hidden_dim]) #(batch, hidden)
        a_emb_final = a_emb + a_emb_noise
    else:
        a_emb_final = params["attribute_embedding"] + params["attribute_noise_embedding"]
    
    '''
    dropout for embedding layer
    '''
    v_emb_final = tf.nn.dropout(v_emb_final, dropout_keep_prob)
    a_emb_final = tf.nn.dropout(a_emb_final, dropout_keep_prob)

    '''
    residual FFN layer
    '''
    h_0 = tf.concat([v_emb_final, a_emb_final], 1) # (batch, 2*hidden)
    h_1 = tf.layers.dense(tf.contrib.layers.layer_norm(h_0, begin_norm_axis = 1, begin_params_axis = -1), units = 2*hidden_dim, activation = tf.nn.relu, use_bias=True) #(batch, hidden)    
    h_1 = tf.add(h_0, tf.nn.dropout(h_1, dropout_keep_prob)) #(batch, hidden)

    '''
    prediction layer
    '''
    q_pred = tf.layers.dense(tf.contrib.layers.layer_norm(h_1, begin_norm_axis = 1, begin_params_axis = -1), units = 1, activation = tf.nn.tanh, use_bias=True) #(batch, 1)
    q_pred = (0.5*N - 0.5)*q_pred + 0.5*N + 0.5 #rescaled tanh

    '''
    summarizing batch loss
    '''
    this_batch_size = tf.cast(tf.shape(q_pred)[0], tf.float32)
    if q_real != None:
        loss = tf.reduce_sum(tf.square(tf.subtract(q_real, q_pred)))/this_batch_size
        loss = loss*batch_size
    else:
        loss = None

    return q_pred, loss

def EstPnQ(params):
    '''
    The NCF approach is too slow when estimating the full matrices, hence we replace that with a quicker multiplication form.
    With well trained user/item/attribute embeddings, we find that there are no obvious differences in the actual recommendation performance. 
    '''
    with tf.device("/CPU:0"):
        P = tf.nn.tanh(tf.matmul(params["user_embedding"] + params['user_noise_embedding'], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        P = (0.5*N - 0.5)*P + 0.5*N + 0.5
        Q = tf.nn.tanh(tf.matmul(params["item_embedding"] + params["item_noise_embedding"], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        Q = (0.5*N - 0.5)*Q + 0.5*N + 0.5
        
        assign_op_P = tf.assign(params["P"], P)
        assign_op_Q = tf.assign(params["Q"], Q)
    return assign_op_P, assign_op_Q

def A2CF(params, u_query, v_query, v_candidate): #input format: 1*(u_query, v_query, v+) + 8*(u_query, v_query, v-)
    '''
    note that due to negative sampling, the batch size here is now (1+neg_size)*orginal_batch_size
    embedding layer
    '''
    u_query_emb = tf.reshape(tf.nn.embedding_lookup(params["user_embedding"], u_query), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["user_noise_embedding"], u_query), [-1, hidden_dim]) 
    v_query_emb = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], v_query), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], v_query), [-1, hidden_dim])
    v_candidate_emb = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], v_candidate), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], v_candidate), [-1, hidden_dim]) #(batch, hidden)

    '''
    fetch corresponding lines from P and Q
    '''
    p_query = tf.reshape(tf.nn.embedding_lookup(params["P"], u_query), [-1, attribute_dim])
    q_query = tf.reshape(tf.nn.embedding_lookup(params["Q"], v_query), [-1, attribute_dim])
    q_candidate = tf.reshape(tf.nn.embedding_lookup(params["Q"], v_candidate), [-1, attribute_dim]) #(batch, attr_size)
    
    '''
    calculate substitution affinity
    '''
    phi = tf.nn.softmax(tf.multiply(q_query, q_candidate)/beta) #(batch, attr_size)
    v_candidate_tilde_1 = tf.matmul(phi, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_s_temp = tf.concat([tf.multiply(v_query_emb, v_candidate_emb), v_candidate_tilde_1], 1) #(batch, 2*hidden)
    f_s = tf.matmul(f_s_temp, params["s_projection_weight"]) #(batch, 1)

    '''
    calculate personalization affinity
    '''
    ita = tf.nn.softmax(tf.multiply(p_query, q_candidate)/epsilon) #(batch, attr_size)
    v_candidate_tilde_2 = tf.matmul(ita, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_p_temp = tf.concat([tf.multiply(u_query_emb, v_candidate_emb), v_candidate_tilde_2], 1) #(batch, 2*hidden)
    f_p = tf.matmul(f_p_temp, params["p_projection_weight"] + params["p_noise_projection_weight"]) #(batch, 1)

    '''
    BPR-S loss function
    '''
    f_rank = f_s*gamma + f_p*(1-gamma) #(batch, 1)
    f_rank = tf.reshape(f_rank, [-1, 1+neg_size]) #(batch(og), 1+neg_size)
    f_rank_pos, f_rank_neg = tf.split(f_rank, [1, neg_size], 1) #(batch(og), 1) and (batch(og), neg_size)

    this_batch_size = tf.cast(tf.shape(f_rank_pos)[0], tf.float32)
    BPR_loss = tf.sigmoid(tf.subtract(tf.tile(f_rank_pos, [1, neg_size]), f_rank_neg))
    BPR_loss = 0.0 - tf.reduce_sum(tf.log(BPR_loss + 1e-24))/tf.cast(tf.shape(f_rank)[0], tf.float32)
    BPR_loss = (BPR_loss/this_batch_size)*batch_size*neg_size

    return f_rank_pos, f_rank_neg, BPR_loss

'''
get the predictions
'''
if (not adv) or (adv and adv_method.upper() == 'FGSM'):
    p_pred, p_loss = UACF(params, u_UACF, a_UACF, p_real, dropout_keep_prob)
    q_pred, q_loss = IACF(params, v_IACF, a_IACF, q_real, dropout_keep_prob)
    new_P, new_Q = EstPnQ(params)
    f_pos, f_neg, BPR_loss = A2CF(params, u_query, v_query, v_candidate)
    
    '''
    optimizer
    '''
    train_opt1 = tf.train.AdamOptimizer(learning_rate = step_size)
    train_op1 = train_opt1.minimize(p_loss + q_loss)
    train_opt2 = tf.train.AdamOptimizer(learning_rate = step_size)
    train_op2 = train_opt2.minimize(BPR_loss)


print("-> tf graph loaded.")
print("-> start training now...")
print("-> Trainable Parameters..")


# Launch the traning session
saver = tf.train.Saver()
with tf.Session() as sess:
    stage = 1
    step = 1
    # Keep training until reach max steps
    best_rec_loss = 1000.0
    best_rec_epoch = 1
    
    out_path = "logs/A2CF/" + str(args.dataset) + "/stage/"
    if adv:
        out_path += "adv_" + adv_method.upper() + '=' + str(eps) + "_"
    
    Path(out_path).mkdir(parents=True, exist_ok=True)
    
    #initialize all parameters before the training loop starts
    if adv and adv_method.upper() == 'RANDOM':
        saver.restore(sess, args.model_path)
        print("-> vanilla model restored.")
        print("-> Total model parameters loaded from vanilla model")
        print_total_parameters(params, adv)
        noises = assign_noise_parameters(params, eps,adv)
        sess.run(noises)
        print("-> After creating all noises:")
        print_total_parameters(params, adv)
        save_path = saver.save(sess, out_path + "/model.ckpt")
        print("-> model saved at the end!")
        sys.exit()
        
    
    
    
    sess.run(tf.global_variables_initializer())
    sess.run(tf.local_variables_initializer())
    
    if adv and adv_method.upper() == 'FGSM':
        # saver.restore(sess, args.model_path)
        print("-> vanilla model restored.")
        
        # print_tensors_in_checkpoint_file(file_name=args.model_path,tensor_name = 'loss',all_tensors = True)
        reader = pywrap_tensorflow.NewCheckpointReader(args.model_path)
        weights = ['user_embedding','item_embedding','helpful_embedding','p_projection_weight', 's_projection_weight']
        _params = [params['user_embedding'],params['item_embedding'],params['attribute_embedding'],params['p_projection_weight'],params['s_projection_weight'], params['P'], params['Q']]
        ops = []
        for param,weight in zip(_params, weights):
            t = reader.get_tensor(weight)
            ops.append(param.assign(t))
            
         
        sess.run(ops)
        print("-> Total model parameters loaded from vanilla model")
        print_total_parameters(params, adv)
        gradsU = assign_gradnoise_parameters(p_loss,[params['user_noise_embedding']],eps)
        gradsI = assign_gradnoise_parameters(q_loss,[params['item_noise_embedding']],eps)
        gradsA = assign_gradnoise_parameters(p_loss + q_loss,[params['attribute_noise_embedding']],eps)
        gradsP = assign_gradnoise_parameters(BPR_loss,[params['p_noise_projection_weight']],eps)
        grads_ = gradsU + gradsI + gradsA
        
    
    verbose = bool(args.verbose)
    loss_uacf = []
    loss_iacf = []
    loss_recon = []
    loss_a2cf = [] 
    num_batches_reconstruct = int(max(len(data_handler.data_UACF),len(data_handler.data_IACF)) // batch_size)
    num_batches_recommend = int(len(data_handler.data_interaction) // batch_size)
    print(" -> Number of batches for reconstructing phase: ",num_batches_reconstruct)
    print(" -> Number of batches for recommending phase: ",num_batches_recommend)
    
    
    
    
    
    while stage <= max_step:
        step = 0
        print("Global Epoch:",int(stage))

        while min(data_handler.epoch_train["UACF"], data_handler.epoch_train["IACF"]) < stage*T_epoch1:
            batch_u_UACF, batch_a_UACF, batch_label_UACF = data_handler.next("UACF", batch_size)
            batch_v_IACF, batch_a_IACF, batch_label_IACF = data_handler.next("IACF", batch_size)
            

            feed_dict = {u_UACF: batch_u_UACF,
                                             a_UACF: batch_a_UACF, 
                                             p_real: batch_label_UACF,
                                             v_IACF: batch_v_IACF,
                                             a_IACF: batch_a_IACF, 
                                             q_real: batch_label_IACF,
                                  dropout_keep_prob: dropout_keep_prob_train}
            
            if adv and adv_method.upper() == 'FGSM':
                
                # grad_vals = [sess.run(gradsU,feed_dict = feed_dict), sess.run(gradsI,feed_dict = feed_dict) , sess.run(gradsA,feed_dict = feed_dict)]
                # grads = assign_gradnoise_parameters(p_loss + q_loss,[params['user_noise_embedding'],params['item_noise_embedding'],params['attribute_noise_embedding']],eps)
                grad_vals = sess.run(grads_,feed_dict = feed_dict)
                if verbose:
                    print("-> NOISE GRAD vals for \nU: ",grad_vals[0].sum(),'\nI:',grad_vals[1].sum(),'\nA:',grad_vals[2].sum())
            
            sess.run(train_op1, feed_dict = feed_dict)
            
            
            '''
            visualize training error
            '''
            if (step > 0 and step % display_step == 0) or (step > 0 and step % num_batches_reconstruct == 0):
                p_loss_vis, q_loss_vis = sess.run([p_loss, q_loss], feed_dict = {u_UACF: batch_u_UACF,
                                                                                 a_UACF: batch_a_UACF, 
                                                                                 p_real: batch_label_UACF,
                                                                                 v_IACF: batch_v_IACF,
                                                                                 a_IACF: batch_a_IACF, 
                                                                                 q_real: batch_label_IACF,
                                                                      dropout_keep_prob: dropout_keep_prob_train})
                
                
                
                
                print("-> (UACF + IACF) stage: " + str(stage) +
                      ", UACF epoch: " + str(int(data_handler.epoch_train["UACF"]) + 1) + " UACF Batch: " + str(int(data_handler.batch_id['UACF'] // batch_size))  +
                      ", IACF epoch: " + str(int(data_handler.epoch_train["IACF"]) + 1) + " IACF Batch: " + str(int(data_handler.batch_id['IACF'] // batch_size)) +
                      "\n   combined loss: " + "{:.3f}".format(p_loss_vis + q_loss_vis) +
                      ", UACF loss: " + "{:.3f}".format(p_loss_vis) +
                      ", IACF loss: " + "{:.3f}".format(q_loss_vis))
                
                
                loss_uacf.append(p_loss_vis)
                loss_iacf.append(q_loss_vis)
                loss_recon.append(p_loss_vis + q_loss_vis)
                
                
            step += 1
        
        
        sess.run([new_P, new_Q])
        if verbose:
            print("--> estimating X and Y...")
            
            print("Sum of X zeros:",(params["P"].eval() == 0).sum())
            print("Sum of Y zeros:",(params["Q"].eval() == 0).sum())
        
        
        
        step = 0
        while data_handler.epoch_train["A2CF"] < stage*T_epoch2:
            batch_u_query, batch_v_query, batch_v_candidate = data_handler.next("A2CF", batch_size) #u_query, v_query, v_candidate
            
            feed_dict2 = {u_query: batch_u_query,
                                             v_query: batch_v_query,
                                         v_candidate: batch_v_candidate}
            
                
            if adv and adv_method.upper() == 'FGSM':
                
                grad_vals2 = sess.run(gradsP,feed_dict = feed_dict2)
                if verbose:
                    print("NOISE GRAD vals for \nW_p:",grad_vals2[0].sum())

            
            sess.run(train_op2,feed_dict = feed_dict2)

            '''
            visualize training error
            '''
            if (step > 0 and step % display_step == 0) or (step > 0 and step % num_batches_recommend == 0):
                
                
                rec_loss_vis = sess.run(BPR_loss, feed_dict = {u_query: batch_u_query,
                                                               v_query: batch_v_query,
                                                           v_candidate: batch_v_candidate})             

                print("-> (A2CF) stage: " + str(stage) +
                      ", A2CF epoch: " + str(int(data_handler.epoch_train["A2CF"]) + 1) + " A2CF batch: " + str(int(data_handler.batch_id['A2CF'] // batch_size)) +
                      "\n   recommendation loss: " + "{:.3f}".format(rec_loss_vis))
                loss_a2cf.append(rec_loss_vis)
                
  
            
            step += 1
        
        
        
        
        stage += 1
        print("="*50)
    
    save_path = saver.save(sess, out_path  + "/model.ckpt")
    print("-> model saved at the end!")
    print("-> training finished.")
    print("-> All params after training:\n")
    print_total_parameters(params,adv)

plot_metrics([loss_uacf,loss_iacf,loss_recon], metric_name = 'Loss-reconstruction', dataset = str(args.dataset), multi = True,names = ['UACF','IACF',"Combined Loss"],model_name = 'A2CF',adv = adv, adv_method = adv_method,eps = eps)  
plot_metrics(loss_a2cf, metric_name = 'Loss-recommender', dataset = str(args.dataset),model_name = 'A2CF',adv = adv, adv_method = adv_method,eps = eps)