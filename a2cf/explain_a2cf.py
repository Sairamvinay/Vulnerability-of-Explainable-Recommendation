from __future__ import print_function
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import tensorflow as tf
from tensorflow.python import pywrap_tensorflow
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import random
import numpy as np
import pickle
from sklearn.metrics import ndcg_score
from sklearn import metrics
import math
import sys
from tqdm import tqdm
import argparse
from pathlib import Path
from util_a2cf import *
sys.path.append("../../data")
from text_processed_dataset import TextProcessedDataset
from yelp_processed_dataset import YelpProcessedDataset
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
print("TF version:",tf.__version__)

def user_side_evaluation(user_perspective_test_data,u_i_exp_dict):
        ave_pre, ave_rec, ave_f1 = evaluate_user_perspective(user_perspective_test_data, u_i_exp_dict)
        print('user\'s perspective:')
        print('ave pre: ', round(ave_pre,6), '  ave rec: ', round(ave_rec,6), '  ave f1: ', round(ave_f1,6))
    
def model_side_evaluation(rec_dict,u_i_exp_dict,sess, predictions, q_final,users,items,feature_vec,masks, rec_dataset,rec_k,args):
    
    test_num = len(list(rec_dict.items()))
    
    ave_pn, ave_ps, ave_fns = evaluate_model_perspective(rec_dict, u_i_exp_dict, sess,predictions, q_final,users,items,feature_vec,masks, rec_dataset.user_feature_matrix, rec_dataset.item_feature_matrix,rec_k,test_num)
    print('model\'s perspective:')
    print('ave PN: ', round(ave_pn,6), '  ave PS: ', round(ave_ps,6), '  ave F_{NS}: ', round(ave_fns,6))  


def args_process():    # Parse argument
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", dest="dataset", type=str, default="electronics",help = 'Name of the dataset')
    parser.add_argument("--adv", dest="adv", type=bool, default = False, help="whether to do adversarial or not")
    parser.add_argument("--adv_method", dest="adv_method", type=str, default = 'FGSM', help="whether to do which adversarial method? Random or FGSM")
    parser.add_argument("--dim", type = int, default = 64, help = 'Hidden Embedding dimensions')
    parser.add_argument("--eps", dest="eps", type=float, default=0.5, help="Error proportion for adversarial training")
    parser.add_argument("--seed", dest="seed", type=int, default=999, help="seed for training")
    parser.add_argument("--data_path",dest = 'data_path', type=str, default ='../data/final-obj/Electronics_dataset_obj.pickle',help = "Path to the dataset for loading")
    parser.add_argument("--model_path", dest="model_path", type=str, default="./logs/",help = 'Load the trained model')
    parser.add_argument("--save_path",dest='save_path',type=str, default = 'expl-obj/', help = 'Where to save the explanations')
    parser.add_argument("--rec_k", dest="rec_k", type=int, default=20,help = 'Top K items to check validation of explanations')
    parser.add_argument("--exp_k", dest="exp_k", type=int, default=20,help = 'Number of aspect explanations')
    parser.add_argument("--test_num", dest="test_num", type=int, default=-1,help = 'Number of test samples')
    args = parser.parse_args()
    return args
def print_total_parameters(params, adv = False):
    total_parameters = 0 
    for param in params:
        variable = params[param]
        shape = variable.get_shape()
        variable_parameters = 1 
        for dim in shape:
            variable_parameters *= dim.value
        print('%s  dim=%i shape=%s params=%i' % ( 
                    variable.name,
                    len(shape),
                    shape,
                    variable_parameters,
                    ))  
        print("Variable value:",variable.eval())
        total_parameters += variable_parameters
    print('total_parameters = %i' % (total_parameters))

    return

def EstPnQ(params):
    '''
    The NCF approach is too slow when estimating the full matrices, hence we replace that with a quicker multiplication form.
    With well trained user/item/attribute embeddings, we find that there are no obvious differences in the actual recommendation performance. 
    '''
    with tf.device("/CPU:0"):
        P = tf.nn.tanh(tf.matmul(params["user_embedding"] + params['user_noise_embedding'], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        P = (0.5*N - 0.5)*P + 0.5*N + 0.5
        Q = tf.nn.tanh(tf.matmul(params["item_embedding"] + params["item_noise_embedding"], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        Q = (0.5*N - 0.5)*Q + 0.5*N + 0.5
        
        assign_op_P = tf.assign(params["P"], P)
        assign_op_Q = tf.assign(params["Q"], Q)
    return assign_op_P, assign_op_Q

# feature_vec is a special matrix mask for removing feature f for an item v (it is otherwise kept all 1s for considering all features)
def get_prediction(params,user, items, feature_vec,hidden_dim,attribute_dim,epsilon,N = 5):
    user_embedding = tf.reshape(tf.nn.embedding_lookup(params["user_embedding"], user), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["user_noise_embedding"], user), [-1, hidden_dim]) 
    item_embedding = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], items), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], items), [-1, hidden_dim]) 
    
    p_query = tf.reshape(tf.nn.embedding_lookup(params["P"], user), [-1, attribute_dim])
    
#     q_candidate = tf.nn.tanh(feature_vec)
#     q_candidate = (0.5*N - 0.5)*q_candidate + 0.5*N + 0.5
    
    q_candidate = tf.reshape(tf.nn.embedding_lookup(params["Q"], items), [-1, attribute_dim]) #(batch, attr_size)

    
    ita = tf.nn.softmax(tf.multiply(p_query, q_candidate)/epsilon, axis = 1) #(batch, attr_size)
    v_candidate_tilde_2 = tf.matmul(ita, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_p_temp = tf.concat([tf.multiply(user_embedding, item_embedding), v_candidate_tilde_2], 1) #(batch, 2*hidden)
    f_p = tf.matmul(f_p_temp, params["p_projection_weight"] + params["p_noise_projection_weight"]) #(batch, 1)
    f_p = tf.sigmoid(f_p)
    return q_candidate, f_p

def cf_prediction(params,user, items, feature_vec,masks,hidden_dim,attribute_dim,epsilon,N = 5):
    user_embedding = tf.reshape(tf.nn.embedding_lookup(params["user_embedding"], user), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["user_noise_embedding"], user), [-1, hidden_dim]) 
    item_embedding = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], items), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], items), [-1, hidden_dim]) 
    
    p_query = tf.reshape(tf.nn.embedding_lookup(params["P"], user), [-1, attribute_dim])
    
#     q_candidate = tf.nn.tanh(feature_vec)
#     q_candidate = (0.5*N - 0.5)*q_candidate + 0.5*N + 0.5
    q_candidate = feature_vec
#     q_candidate = tf.reshape(tf.nn.embedding_lookup(params["Q"], items), [-1, attribute_dim]) #(batch, attr_size)
    ita = tf.nn.softmax(tf.multiply(p_query, q_candidate)/epsilon, axis = 1) #(batch, attr_size)
#     ita = tf.multiply(ita, masks)
    v_candidate_tilde_2 = tf.matmul(ita, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_p_temp = tf.concat([tf.multiply(user_embedding, item_embedding), v_candidate_tilde_2], 1) #(batch, 2*hidden)
    f_p = tf.matmul(f_p_temp, params["p_projection_weight"] + params["p_noise_projection_weight"]) #(batch, 1)
    # f_p = tf.sigmoid(f_p)
    return q_candidate, f_p


def generate_explanations(params, user, item,attribute_dim):
    p_query = tf.reshape(tf.nn.embedding_lookup(params["P"], user), [-1, attribute_dim])
    q_candidate = tf.reshape(tf.nn.embedding_lookup(params["Q"], item), [-1, attribute_dim]) #(batch, attr_size)
    expl = tf.multiply(p_query, q_candidate) #(batch, attr_size)
    return expl
    
'''

network parameters
'''


args = args_process()
print("Args:",args)
with open(args.data_path, 'rb') as handle:
    rec_dataset = pickle.load(handle)

print("DATASET:",args.dataset.upper())
rec_dataset.printDetails()

user_dim = rec_dataset.user_num
item_dim = rec_dataset.item_num
attribute_dim = rec_dataset.feature_num

pos_size = 6 # change based on what test data you use depending on number of positive samples per user
N = 5 # maximum score
hidden_dim = int(args.dim)
beta = 8
epsilon = 8
gamma = 0 # so that we remove item similarity conditions #0.7 # 0<gamma<1
seed = int(args.seed)
adv = bool(args.adv)
adv_method = str(args.adv_method)
eps = float(args.eps)
rec_k = int(args.rec_k)
exp_k = int(args.exp_k)



random.seed(seed)
np.random.seed(seed)
tf.set_random_seed(seed)

test_data = rec_dataset.test_data
user_item_feature_dict = {}  # {(u, i): f, (u, i): f]
# Get the whole user-item-feature information
for row in rec_dataset.sentiment_data:
    user = row[0]
    item = row[1]
    user_item_feature_dict[(user, item)] = []
    for fos in row[2:]:
        feature = fos[0]
        user_item_feature_dict[(user, item)].append(feature)


print("ARGS:",args)

'''
define parameters (weights & biases)
'''
params = {
    #____ embedding weights ____
    "user_embedding": tf.get_variable("user_embedding", shape = [user_dim, hidden_dim], trainable = False, initializer = tf.glorot_uniform_initializer),
    "item_embedding": tf.get_variable("item_embedding", shape = [item_dim, hidden_dim], trainable = False, initializer = tf.glorot_uniform_initializer),
    "attribute_embedding": tf.get_variable("helpful_embedding", shape = [attribute_dim, hidden_dim], trainable = False, initializer = tf.glorot_uniform_initializer),
    #____ noise weights _____
    "user_noise_embedding": tf.get_variable("user_noise_embedding", shape = [user_dim, hidden_dim], trainable = False, initializer = tf.zeros_initializer),
    "item_noise_embedding": tf.get_variable("item_noise_embedding", shape = [item_dim, hidden_dim], trainable = False, initializer = tf.zeros_initializer),
    "attribute_noise_embedding": tf.get_variable("helpful_noise_embedding", shape = [attribute_dim, hidden_dim], trainable = False, initializer = tf.zeros_initializer),
    "p_noise_projection_weight": tf.get_variable("p_noise_projection_weight", shape = [2*hidden_dim, 1], trainable = False, initializer = tf.zeros_initializer),
    
    #____ MF weights ____    
    "s_projection_weight": tf.get_variable("s_projection_weight", shape = [2*hidden_dim, 1], trainable = False, initializer = tf.glorot_uniform_initializer),
    "p_projection_weight": tf.get_variable("p_projection_weight", shape = [2*hidden_dim, 1], trainable = False, initializer = tf.glorot_uniform_initializer)}

with tf.device("/CPU:0"):    
    params["P"] = tf.get_variable("P", trainable = False, initializer = tf.zeros([user_dim, attribute_dim]), caching_device = "/CPU:0")
    params["Q"] = tf.get_variable("Q", trainable = False, initializer = tf.zeros([item_dim, attribute_dim]), caching_device = "/CPU:0")
    

users = tf.placeholder("int32", [None, 1]) #(batch, 1)
items = tf.placeholder("int32", [None, 1]) #(batch, 1)
feature_vec = tf.placeholder("float32",[None, attribute_dim])
masks = tf.placeholder("float32",[None, attribute_dim])
if adv:
    print("ADVERSARIAL MODEL USED: ",args.model_path)

else:
    print("SIMPLE MODEL USED: ",args.model_path)

q_final_, predictions = get_prediction(params, users, items,feature_vec,hidden_dim,attribute_dim, epsilon)
q_final, predictions_cf = cf_prediction(params, users, items,feature_vec,masks,hidden_dim,attribute_dim, epsilon)
explanations = generate_explanations(params, users, items,attribute_dim)

with tf.Session() as sess:
    reader = pywrap_tensorflow.NewCheckpointReader(args.model_path)
    weights = ['user_embedding','item_embedding','helpful_embedding','p_projection_weight', 's_projection_weight','user_noise_embedding','item_noise_embedding','helpful_noise_embedding','p_noise_projection_weight']
    _params = [params['user_embedding'],params['item_embedding'],params['attribute_embedding'],params['p_projection_weight'],params['s_projection_weight'],params['user_noise_embedding'],params['item_noise_embedding'],params['attribute_noise_embedding'],params['p_noise_projection_weight']]
    ops = [] #load all the weights
    for param,weight in zip(_params, weights):
        t = reader.get_tensor(weight)
        ops.append(param.assign(t))


    sess.run(ops)
    new_P, new_Q = EstPnQ(params)
    sess.run([new_P, new_Q])
    
    
    rec_dict = {}
    u_i_expl_dict = {}
    correct_rec_dict = {}  # used for user-side evaluation
    
    
    if args.test_num == -1:
        test_num = user_dim
    else:
        test_num = args.test_num
    
    print("Recommending first and storing top K")
    for i,row in (enumerate(test_data[:])):
        batch_user = row[0]
        batch_items = row[1]
        labels = np.array(row[2])
        correct_rec_dict[batch_user] = []
        
        batch_users = [batch_user for _ in range(len(batch_items))]
        batch_users = np.array(batch_users).reshape((-1,1))
                
        masking = np.ones((len(batch_items), attribute_dim))
        
        scores = sess.run([predictions],feed_dict = {users: batch_users, items: np.array(batch_items).reshape((-1,1)), feature_vec: masking})
        scores = np.array(scores).ravel()
        sort_index = sorted(range(len(scores)), key=lambda x: scores[x], reverse=True)
        sorted_items = [batch_items[j] for j in sort_index]
        rec_dict[batch_user] = sorted_items
        if i < 5:
            print("recommendation for user:",batch_user," :",list(zip(sorted_items,labels[sort_index], scores[sort_index]))[:rec_k])
        
        for i in range(rec_k):  # find the correct items and add to the user side test data
            if labels[sort_index[i]] == 1:
                correct_rec_dict[batch_user].append(batch_items[sort_index[i]])
        
    print("Finished recommendations!")
    user_perspective_test_data = {}  # {(u, i):f, (u, i): f]}
    for batch_user, batch_items in correct_rec_dict.items():
        for item in batch_items:
            feature = user_item_feature_dict[(batch_user, item)]
            user_perspective_test_data[(batch_user, item)] = feature
    
    if args.test_num == -1:
        test_num = len(list(rec_dict.items()))
    else:
        test_num = args.test_num
    
    print("Beginning for generating all the explanations!\n")
    for i, (user,rec_items) in tqdm(enumerate(list(rec_dict.items())[:test_num])):
        for item in rec_items[:rec_k]:
            scores_explanation_features = sess.run(explanations, feed_dict = {users:[[user]], items:[[item]]})
            scores_explanation_features = np.array(scores_explanation_features).ravel()
            explanation_features_all = list(zip(list(range(attribute_dim)), scores_explanation_features))
            explanation_features_all.sort(key = lambda x: x[1], reverse = True)
            
            explanation_features, _ = zip(*explanation_features_all)
            print('explanation for user %d and item %d' % (user, item), end = ',')
            print("features:",explanation_features[:exp_k])
            u_i_expl_dict[(user,item)] = explanation_features[:exp_k]
        print("="*50)
        
    
    print("Generated all the explanations!")
    print("Time to evaluate now")
    user_side_evaluation(user_perspective_test_data,u_i_expl_dict)
#     model_side_evaluation(rec_dict,u_i_expl_dict,sess, predictions_cf, q_final,users,items,feature_vec,masks, rec_dataset,rec_k,args)

dir_name = str(args.save_path) + str(args.dataset)
if adv:
    dir_name += "_" + str(adv_method.upper()) + "_" + str(eps)

name = dir_name + "/explanation_obj.pickle"
Path(dir_name).mkdir(parents=True, exist_ok=True)

with open(name, 'wb') as outp:
    pickle.dump([u_i_expl_dict,rec_dict], outp, pickle.HIGHEST_PROTOCOL)
