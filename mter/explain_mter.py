import os
import math
import random
import pickle
import argparse
from pathlib import Path
import numpy as np
from util_mter import *
import sys
from tqdm import tqdm
sys.path.append("../../data")
from text_processed_dataset import TextProcessedDataset
from yelp_processed_dataset import YelpProcessedDataset
os.environ['CUDA_VISIBLE_DEVICES'] = '2'

def single_get_value(G,U,I,F,index):
    tensor_value1 = np.einsum('abc, a -> bc', G, U[index[0]])
    tensor_value2 = np.einsum('bc, b -> c', tensor_value1, I[index[1]])
    return np.einsum('c, c -> ', tensor_value2, F[index[2]])


def get_value(G,U,I,F,index):
    score = 0
    
    dim1,dim2,dim3 = G.shape
    u_idx,i_idx,a_idx = index[0],index[1],index[2]
    for i in range(dim1):
        for j in range(dim2):
            for k in range(dim3):
                score = score + G[i, j, k] * U[u_idx, i] * I[i_idx, j] * F[a_idx, k]
    return score

def args_process():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_path', default='../../data/final-obj/Electronics_dataset_obj.pickle', type=str, help='data object path')
    parser.add_argument('--dataset', default='Electronics', type=str, help='Dataset Name')
    parser.add_argument('--adv', default=False, type=bool, help='use adv method or not?')
    parser.add_argument('--adv_method', default='random', type=str, help='which adv method')
    parser.add_argument("--seed", dest="seed", type=int, default=999, help="seed")
    parser.add_argument("--rec_k", dest="rec_k", type=int, default=20, help="length of rec list")
    parser.add_argument("--exp_k", dest="exp_k", type=int, default=50, help="length of expl list")
    parser.add_argument("--eps", dest="eps", type=float, default=1, help="noise level")
    parser.add_argument("--test_num", dest="test_num", type=int, default=-1, help="length of testing set")
    parser.add_argument("--base_model_path", dest="base_model_path", type=str, default="./logs/",help = 'path to vanilla model')    
    args = parser.parse_args()
    return args

if __name__ == '__main__':

    args = args_process()
    print("Args:",args)
    save_path = str("expl-objs/")
    with open(args.data_path,'rb') as handle:
        rec_dataset = pickle.load(handle)
    
    print("DATASET:",args.dataset.upper())
    rec_dataset.printDetails()
    
    
    with open(args.base_model_path,'rb') as handle:
        params = pickle.load(handle)
    
    # load trained model parameters
    G1 = params['G1']
    U = params['U']
    I = params['I']
    A = params['F']
    G2 = params['G2']
    G3 = params['G3']
    W = params['W']
    
    if args.adv:
        U += params['Unoise']
        I += params['Inoise']
        A += params['Fnoise']
        
        U[U < 0] = 0
        I[I < 0] = 0
        A[A < 0] = 0
         
    
    
    rec_k = int(args.rec_k)
    exp_k = int(args.exp_k)
    
    test_data = rec_dataset.test_data
    
    U_num = rec_dataset.user_num
    I_num = rec_dataset.item_num
    F_num = rec_dataset.feature_num  #+1 including overall rating
    W_num = rec_dataset.opinions_num 
    
    seed = int(args.seed)
    random.seed(seed)
    np.random.seed(seed)
        
    
    user_item_feature_dict = {}  # {(u, i): f, (u, i): f]
    # Get the whole user-item-feature information
    for row in rec_dataset.sentiment_data:
        user = row[0]
        item = row[1]
        user_item_feature_dict[(user, item)] = []
        for fos in row[2:]:
            feature = fos[0]
            user_item_feature_dict[(user, item)].append(feature)
    
    
    u_inds = []
    i_inds = []
    a_inds = []
    gt_inds = []
    num_test_items = 0
    
    if args.test_num == -1:
        num_users = len(test_data) 
    
    else:
        num_users = args.test_num
    
    # 1. Recommendations (top K) ; 2. For all these recommendations; we find best K features from Xhat i,j, k for all k those correspond to features but the last dimension which is the prediction! 3. Do the user perspective data and then best explanations.
    for row in (test_data[:num_users]):
        user = row[0]
        items,gt_labels = row[1],row[2]
        
        if user == 0:
            num_test_items = len(items)
        
        
        i_inds += items.ravel().tolist()
        u_inds += [user for _ in items]
        a_inds += [-1 for _ in items]
        gt_inds += gt_labels.ravel().tolist()
    
    print("Recommending now...")
    print("Doing calculation now..")
    scores = faster_get_value(G1,U,I,A,(u_inds,i_inds,a_inds))
    scores = np.array(scores)
    print("DONE..")
    
    rec_dict = {}
    u_i_expl_dict = {}
    correct_rec_dict = {}
    for index,row in enumerate(test_data[:num_users]):
        user = row[0]
        items = row[1]
        correct_rec_dict[user] = []
        scores_user = scores[index * num_test_items: (index + 1) * num_test_items]
        labels_user = gt_inds[index * num_test_items: (index + 1) * num_test_items]
        triple = [(item,ground,score) for item,ground,score in list(zip(items,labels_user,scores_user))]
        triple.sort(key = lambda x: x[2],reverse= True)
        rec_dict[user] = triple[:rec_k]
        if user < 5:
            print("recommendation for user:",user," :",rec_dict[user])
        
        for i in range(rec_k):  # find the correct items and add to the user side test data
            curr_item_vals = triple[i]
            item,label,score = curr_item_vals
            if label == 1:
                correct_rec_dict[user].append(item)
    
    print("Finished recommendations!")
    user_perspective_test_data = {}  # {(u, i):f, (u, i): f]}
    for batch_user, batch_items in correct_rec_dict.items():
        for item in batch_items:
            feature = user_item_feature_dict[(batch_user, item)]
            user_perspective_test_data[(batch_user, item)] = feature
    
    # Key things: WE have to construct Xhat matrix for each of the U,I pairs (find values for all the features)
    print("Beginning for generating all the explanations!\n")
    for i, (user,rec_items) in tqdm(enumerate(list(rec_dict.items())[:num_users])):
        
#         for item,_,_ in rec_items[:rec_k]:
            
#             explanation_features_all = {}
#             # Xhat = faster_get_value(G1,U,I,A,(users,[item for _ in range(F_num)],list(range(F_num))))
#             for feature in range(F_num):
#                 score = get_value(G1,U,I,A,(user,item,feature))
#                 explanation_features_all[feature] = score
            
#             all_feats = list(explanation_features_all.items())
#             all_feats.sort(key = lambda x: x[1],reverse= True)
#             explanation_features,Xhat = zip(*all_feats)
                
#             # explanation_features = np.argsort(Xhat)
#             print('explanation for user %d and item %d' % (user, item), end = ',')
#             print("features:",explanation_features[:exp_k], ' scores: ',Xhat[:exp_k])
#             u_i_expl_dict[(user,item)] = explanation_features[:exp_k]
#         print("="*50)

        users = [user for _ in range(F_num + 1)]
        
        for item,_,_ in rec_items[:rec_k]:
            explanation_features = []
            Xhat = faster_get_value(G1,U,I,A,(users,[item for _ in range(F_num + 1)],list(range(F_num + 1))))
            Xhat,pred = Xhat[:-1],Xhat[-1]
            Xhat = np.array(Xhat)
            expl_all = list(zip(list(range(F_num)),Xhat))
            expl_all.sort(reverse = True, key = lambda x:x[1])
            explanation_features,scores = list(zip(*expl_all))
            print('explanation for user %d and item %d and score %f' % (user, item,pred), end = ',')
            print("features:",explanation_features[:exp_k], ' scores: ',scores[:exp_k])
#             word_agg = []
#             for feature in explanation_features[:50]:
#                 Yhat_u = faster_get_value(G2,U,A,W,([user]*W_num,[feature]*W_num, list(range(W_num))))
#                 Yhat_i = faster_get_value(G3,I,A,W,([item]*W_num,[feature]*W_num, list(range(W_num))))
#                 orig_word_scores = Yhat_u * Yhat_i
#                 word_agg.append(orig_word_scores.sum())
#                 word_all = list(zip(list(range(W_num)),orig_word_scores))
#                 word_all.sort(reverse = True, key = lambda x:x[1])
#                 top_words,word_scores = list(zip(*word_all))
                
                
#                 print('explanation for user %d and item %d' % (user, item), end = ',')
#                 print("features:",feature, ' words: ',top_words[:exp_k], ' word scores: ',word_scores[:exp_k])
            
#             final_expl = np.array(word_agg) * scores[:50]
#             final_all = list(zip(explanation_features[:50],final_expl))
#             final_all.sort(reverse = True, key = lambda x:x[1])
#             top_feats,scores_weight = list(zip(*final_all))
            
            
#             print("After weighting: features: ",top_feats[:exp_k], ' scores: ',scores_weight[:exp_k])
            
            u_i_expl_dict[(user,item)] = explanation_features[:exp_k]
        print("="*50)
        
        
    
    print("Generated all the explanations!")
    print("Time to evaluate now")
    
    ave_pre, ave_rec, ave_f1 = evaluate_user_perspective(user_perspective_test_data,u_i_expl_dict)
    print('user\'s perspective:')
    print('ave pre: ', round(ave_pre,6), '  ave rec: ', round(ave_rec,6), '  ave f1: ', round(ave_f1,6))
    dir_name = str(save_path) + str(args.dataset)
    if args.adv:
        dir_name += "_" + str(args.adv_method.upper()) + "_" + str(args.eps)

    name = dir_name + "/explanation_obj.pickle"
    Path(dir_name).mkdir(parents=True, exist_ok=True)
    
    outputs = (rec_dict,u_i_expl_dict)

    with open(name, 'wb') as outp:
        pickle.dump(outputs, outp, pickle.HIGHEST_PROTOCOL)
    