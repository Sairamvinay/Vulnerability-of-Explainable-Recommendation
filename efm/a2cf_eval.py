from __future__ import print_function
import tensorflow as tf
import random
import numpy as np
import pickle
import sklearn
from numpy import array
from sklearn import metrics
import math
import sys
import os
from util_a2cf import find_validation_data
import argparse
sys.path.append("../data")
from text_processed_dataset import TextProcessedDataset
from yelp_processed_dataset import YelpProcessedDataset
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
print("TF version:",tf.__version__)

def args_process():    # Parse argument
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", dest="dataset", type=str, default="electronics",help = 'Name of the dataset')
    parser.add_argument("--adv", dest="adv", type=bool, default = False, help="whether to do adversarial or not")
    parser.add_argument("--adv_method", dest="adv_method", type=str, default = 'FGSM', help="whether to do which adversarial method? Random or FGSM")
    parser.add_argument("--print_every",dest = "print_every",type = int, default = 10, help = 'print every x batches once')
    parser.add_argument("--neg_size", type = int, default =100, help = 'Negative samples per one positive sample for testing')
    parser.add_argument("--dim", type = int, default = 64, help = 'Hidden Embedding dimensions')
    parser.add_argument("--eps", dest="eps", type=float, default=0.5, help="Error proportion for adversarial training")
    parser.add_argument("--seed", dest="seed", type=int, default=999, help="seed for training")
    parser.add_argument("--batch_size", dest="batch_size", type=int, default=1, help="batch size for testing base rec model")
    parser.add_argument("--data_path",dest = 'data_path', type=str, default ='../data/final-obj/Electronics_dataset_obj.pickle',help = "Path to the dataset for loading")
    parser.add_argument("--rec_k", dest="rec_k", type=int, default=20, help="length of rec list")
    parser.add_argument("--model_path", dest="model_path", type=str, default="./logs/",help = 'Load the trained model')
    args = parser.parse_args()
    return args


def print_total_parameters(params, adv = False):
    total_parameters = 0 
    
    if not adv:
        for variable in tf.trainable_variables():
            # shape is an array of tf.Dimension
            shape = variable.get_shape()
            variable_parameters = 1 
            for dim in shape:
                variable_parameters *= dim.value
            print('%s  dim=%i shape=%s params=%i' % ( 
                        variable.name,
                        len(shape),
                        shape,
                        variable_parameters,
                        ))  
            print("Variable value:",variable.eval())
            total_parameters += variable_parameters
        print('total_parameters = %i' % (total_parameters))

        print("-> NOISE PARAMS:")
        for n in tf.global_variables():
            if 'noise' in n.name:
                variable_parameters = 1 
                shape = n.get_shape()
                for dim in shape:
                    variable_parameters *= dim.value
                print(n.name, ' dim:',len(shape), ' shape:',shape, ' params:',variable_parameters,' value: ',n.eval())
    
    else:
        for param in params:
            variable = params[param]
            variable_parameters = 1 
            shape = variable.get_shape()
            for dim in shape:
                variable_parameters *= dim.value
            print(variable.name, 'is trainable:',variable.trainable, " dim:",len(shape), " params:", variable_parameters,' value:',variable.eval())
    
    
    return

##############
#data handler#
##############
class DataHandler(object):

    def __init__(self, test_data, test_size = 5):
        '''
        initialize all data
        '''
        self.data_interaction = []
        '''
        new feature format:
        [ 
        line 0, 1, 2: [query user (int), query item (int), real item (int)]
        line 3 ~ -1: [negtive poi (int)]
        ]
        '''
        print("-> loading only validation interaction data now...")
        self.data_interaction = find_validation_data(test_data, test_size = test_size)
        random.shuffle(self.data_interaction)    
        self.sample_num = len(self.data_interaction)
        self.neg_num = len(self.data_interaction[0][3:])
        print("SAMPLE NUM:",self.sample_num)
        print("NEG num:",self.neg_num)
        self.batch_id = 0
        print("-> all data loaded.")

    def next(self):
        '''
        Return one test sample at a time.
        '''
        if self.batch_id == len(self.data_interaction):
            self.batch_id = 0

        batch_feature = self.data_interaction[self.batch_id]
        batch_first_section = [[batch_feature[0]] for x in range(self.neg_num + 1)]
        batch_second_section = [[batch_feature[1]] for x in range(self.neg_num + 1)]
        batch_third_section = [[x] for x in batch_feature[2:]] #1 + 1000 test cases

        self.batch_id = min(self.batch_id + 1, len(self.data_interaction))
        return batch_first_section, batch_second_section, batch_third_section

'''

network parameters
'''
args = args_process()
print("Args:",args)
with open(args.data_path, 'rb') as handle:
    rec_dataset = pickle.load(handle)

print("DATASET:",args.dataset.upper())
rec_dataset.printDetails()

user_dim = rec_dataset.user_num
item_dim = rec_dataset.item_num
attribute_dim = rec_dataset.feature_num

neg_size = int(args.neg_size)
pos_size = 6 # change based on what test data you use depending on number of positive samples per user
N = 5 # maximum score
batch_size = int(args.batch_size)
hidden_dim = int(args.dim)
beta = 8
epsilon = 8
gamma = 0 # so that we remove item similarity conditions #0.7 # 0<gamma<1
seed = int(args.seed)
adv = bool(args.adv)
adv_method = str(args.adv_method)
eps = float(args.eps)
print_every = int(args.print_every)
random.seed(seed)
np.random.seed(seed)
tf.set_random_seed(seed)


print("ARGS:",args)

'''
load and split data
'''
data_handler = DataHandler(rec_dataset.test_data)
print("-> loading the tf graph now...")

'''
running parameters
'''
display_step = int(args.print_every)

'''
tf graph input
'''
u_query = tf.placeholder("int32", [None, 1]) #(batch, 1)
v_query = tf.placeholder("int32", [None, 1]) #(batch, 1)
v_candidate = tf.placeholder("int32", [None, 1]) #(batch, 1)
u_UACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
a_UACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
p_real = tf.placeholder("float", [None, 1]) #(batch, 1)
v_IACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
a_IACF = tf.placeholder("int32", [None, 1]) #(batch, 1)
q_real = tf.placeholder("float", [None, 1]) #(batch, 1)


'''
define parameters (weights & biases)
'''
params = {
    #____ embedding weights ____
    "user_embedding": tf.get_variable("user_embedding", shape = [user_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    "item_embedding": tf.get_variable("item_embedding", shape = [item_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    "attribute_embedding": tf.get_variable("helpful_embedding", shape = [attribute_dim, hidden_dim], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer),
    #____ noise weights _____
    "user_noise_embedding": tf.get_variable("user_noise_embedding", shape = [user_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "item_noise_embedding": tf.get_variable("item_noise_embedding", shape = [item_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "attribute_noise_embedding": tf.get_variable("helpful_noise_embedding", shape = [attribute_dim, hidden_dim], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    "p_noise_projection_weight": tf.get_variable("p_noise_projection_weight", shape = [2*hidden_dim, 1], trainable = bool(args.adv), initializer = tf.zeros_initializer),
    
    #____ MF weights ____    
    "s_projection_weight": tf.get_variable("s_projection_weight", shape = [2*hidden_dim, 1], trainable = True, initializer = tf.glorot_uniform_initializer),
    "p_projection_weight": tf.get_variable("p_projection_weight", shape = [2*hidden_dim, 1], trainable = not bool(args.adv), initializer = tf.glorot_uniform_initializer)}

with tf.device("/CPU:0"):    
    params["P"] = tf.get_variable("P", trainable = False, initializer = tf.zeros([user_dim, attribute_dim]), caching_device = "/CPU:0")
    params["Q"] = tf.get_variable("Q", trainable = False, initializer = tf.zeros([item_dim, attribute_dim]), caching_device = "/CPU:0")
    
def EstPnQ(params):
    '''
    The NCF approach is too slow when estimating the full matrices, hence we replace that with a quicker multiplication form.
    With well trained user/item/attribute embeddings, we find that there are no obvious differences in the actual recommendation performance. 
    '''
    with tf.device("/CPU:0"):
        P = tf.nn.tanh(tf.matmul(params["user_embedding"] + params['user_noise_embedding'], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        P = (0.5*N - 0.5)*P + 0.5*N + 0.5
        Q = tf.nn.tanh(tf.matmul(params["item_embedding"] + params["item_noise_embedding"], tf.transpose(params["attribute_embedding"] + params["attribute_noise_embedding"])))
        Q = (0.5*N - 0.5)*Q + 0.5*N + 0.5
        
        assign_op_P = tf.assign(params["P"], P)
        assign_op_Q = tf.assign(params["Q"], Q)
    return assign_op_P, assign_op_Q

def A2CF(params, u_query, v_query, v_candidate): #input format: 1*(u_query, v_query, v+) + 8*(u_query, v_query, v-)
    '''
    note that due to negative sampling, the batch size here is now (1+neg_size)*orginal_batch_size
    embedding layer
    '''
    u_query_emb = tf.reshape(tf.nn.embedding_lookup(params["user_embedding"], u_query), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["user_noise_embedding"], u_query), [-1, hidden_dim]) 
    v_query_emb = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], v_query), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], v_query), [-1, hidden_dim])
    v_candidate_emb = tf.reshape(tf.nn.embedding_lookup(params["item_embedding"], v_candidate), [-1, hidden_dim]) + tf.reshape(tf.nn.embedding_lookup(params["item_noise_embedding"], v_candidate), [-1, hidden_dim]) #(batch, hidden)

    '''
    fetch corresponding lines from P and Q
    '''
    p_query = tf.reshape(tf.nn.embedding_lookup(params["P"], u_query), [-1, attribute_dim])
    q_query = tf.reshape(tf.nn.embedding_lookup(params["Q"], v_query), [-1, attribute_dim])
    q_candidate = tf.reshape(tf.nn.embedding_lookup(params["Q"], v_candidate), [-1, attribute_dim]) #(batch, attr_size)
    
    '''
    calculate substitution affinity
    '''
    phi = tf.nn.softmax(tf.multiply(q_query, q_candidate)/beta) #(batch, attr_size)
    v_candidate_tilde_1 = tf.matmul(phi, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_s_temp = tf.concat([tf.multiply(v_query_emb, v_candidate_emb), v_candidate_tilde_1], 1) #(batch, 2*hidden)
    f_s = tf.matmul(f_s_temp, params["s_projection_weight"]) #(batch, 1)

    '''
    calculate personalization affinity
    '''
    ita = tf.nn.softmax(tf.multiply(p_query, q_candidate)/epsilon) #(batch, attr_size)
    v_candidate_tilde_2 = tf.matmul(ita, params["attribute_embedding"] + params["attribute_noise_embedding"]) #(batch, hidden)
    f_p_temp = tf.concat([tf.multiply(u_query_emb, v_candidate_emb), v_candidate_tilde_2], 1) #(batch, 2*hidden)
    f_p = tf.matmul(f_p_temp, params["p_projection_weight"] + params["p_noise_projection_weight"]) #(batch, 1)

    '''
    BPR-S loss function
    '''
    f_rank = f_s*gamma + f_p*(1-gamma) #(batch, 1)
    f_rank = tf.reshape(f_rank, [-1, 1+neg_size]) #(batch(og), 1+neg_size)
    f_rank_pos, f_rank_neg = tf.split(f_rank, [1, neg_size], 1) #(batch(og), 1) and (batch(og), neg_size)
    f_rank_pos = tf.sigmoid(f_rank_pos) #added for evaluation comparison
    f_rank_neg = tf.sigmoid(f_rank_neg) #added for evaluation comparison
    return f_rank_pos, f_rank_neg

'''
get the predictions
'''
new_P, new_Q = EstPnQ(params)
f_pos, f_neg = A2CF(params, u_query, v_query, v_candidate)

print("-> tf graph loaded.")
print("-> start testing now...")

'''
start testing with recovered model parameters
'''
saver = tf.train.Saver()


with tf.Session() as sess:
    saver.restore(sess, str(args.model_path))
    print("-> model restored.")
    print_total_parameters(params, args.adv)
    sess.run([new_P, new_Q]) #precompute P and Q
    # Keep training until reach max steps
    all_hits = {1:0, 5:0.0, 10:0.0, 20:0.0, 50:0.0, 100:0.0}
    all_mrr = {1:0, 5:0.0, 10:0.0, 20:0.0, 50:0.0, 100:0.0}
    all_ndcg = {1:0, 5:0.0, 10:0.0, 20:0.0, 50:0.0, 100:0.0}
    user_hits = {}
    user_mrr = {}
    user_ndcg = {}
    per_user_hits = {}
    per_user_ndcg = {}
    per_user_mrr = {}
    for k in [1,5, 10, 20, 50, 100]:
        per_user_hits[k] = 0
        user_hits[k] = 0
        per_user_mrr[k] = 0
        user_mrr[k] = 0
        per_user_ndcg[k] = 0
        user_ndcg[k] = 0
    
    while data_handler.batch_id < data_handler.sample_num:
        batch_u_query, batch_v_query, batch_v_candidate = data_handler.next()

        score_pos_og, score_neg = sess.run([f_pos, f_neg], feed_dict = {u_query: batch_u_query,
                                                                        v_query: batch_v_query,
                                                                    v_candidate: batch_v_candidate})
        
        score_pos = score_pos_og[0,0]
        score_neg = np.fliplr(np.sort(score_neg))
        
        
        
        if score_pos >= score_neg[0,99]:
            per_user_hits[100] += 1.0
            all_hits[100] += 1.0
            if score_pos >= score_neg[0,49]:
                per_user_hits[50] += 1.0
                all_hits[50] += 1.0
                if score_pos >= score_neg[0,19]:
                    per_user_hits[20] += 1.0
                    all_hits[20] += 1.0
                    if score_pos >= score_neg[0,9]:
                        per_user_hits[10] += 1.0
                        all_hits[10] += 1.0
                        if score_pos >= score_neg[0,4]:
                            per_user_hits[5] += 1.0
                            all_hits[5] += 1.0
                            if score_pos >= score_neg[0,0]:
                                per_user_hits[1] += 1.0
                                all_hits[1] += 1.0
        
        for i in range(100):
            if score_pos >= score_neg[0,i]:
                mrr = 1.0/(1 + float(i+1))
                score_pos = -10000.0
                if i <= 99:
                    per_user_mrr[100] += mrr
                    all_mrr[100] += mrr
                    if i <= 49:
                        per_user_mrr[50] += mrr
                        all_mrr[50] += mrr
                        if i <= 19:
                            per_user_mrr[20] += mrr
                            all_mrr[20] += mrr
                            if i <= 9:
                                per_user_mrr[10] += mrr
                                all_mrr[10] += mrr
                                if i <= 4:
                                    per_user_mrr[5] += mrr
                                    all_mrr[5] += mrr
                                    if i == 1:
                                        per_user_mrr[1] += mrr
                                        all_mrr[1] += mrr

        score_pos = score_pos_og[0,0]
        for i in range(100):
            if score_pos >= score_neg[0,i]:
                ndcg = 1.0/math.log((1 + float(i+1)), 2.0)
                score_pos = -10000.0
                if i <= 99:
                    per_user_ndcg[100] += ndcg
                    all_ndcg[100] += ndcg
                    if i <= 49:
                        per_user_ndcg[50] += ndcg
                        all_ndcg[50] += ndcg
                        if i <= 19:
                            per_user_ndcg[20] += ndcg
                            all_ndcg[20] += ndcg
                            if i <= 9:
                                per_user_ndcg[10] += ndcg
                                all_ndcg[10] += ndcg
                                if i <= 4:
                                    per_user_ndcg[5] += ndcg
                                    all_ndcg[5] += ndcg
                                    if i == 1:
                                        per_user_ndcg[1] += ndcg
                                        all_ndcg[1] += ndcg
        
        if data_handler.batch_id % pos_size == 0:
            
            for k in [1,5, 10, 20, 50, 100]:
                user_hits[k] += (per_user_hits[k] / float(pos_size))
                user_mrr[k] += (per_user_mrr[k] / float(pos_size))
                user_ndcg[k] += (per_user_ndcg[k] / float(pos_size))
                per_user_hits[k] = 0
                per_user_mrr[k] = 0
                per_user_ndcg[k] = 0
        
        if data_handler.batch_id % print_every == 0:
            hit1_avg = all_hits[1]/float(data_handler.batch_id)
            hit5_avg = all_hits[5]/float(data_handler.batch_id)
            hit10_avg = all_hits[10]/float(data_handler.batch_id)
            hit20_avg = all_hits[20]/float(data_handler.batch_id)
            hit50_avg = all_hits[50]/float(data_handler.batch_id)
            hit100_avg = all_hits[100]/float(data_handler.batch_id)

            mrr1_avg = all_mrr[1]/float(data_handler.batch_id)
            mrr5_avg = all_mrr[5]/float(data_handler.batch_id)
            mrr10_avg = all_mrr[10]/float(data_handler.batch_id)
            mrr20_avg = all_mrr[20]/float(data_handler.batch_id)
            mrr50_avg = all_mrr[50]/float(data_handler.batch_id)
            mrr100_avg = all_mrr[100]/float(data_handler.batch_id)

            ndcg1_avg = all_ndcg[1]/float(data_handler.batch_id)
            ndcg5_avg = all_ndcg[5]/float(data_handler.batch_id)
            ndcg10_avg = all_ndcg[10]/float(data_handler.batch_id)
            ndcg20_avg = all_ndcg[20]/float(data_handler.batch_id)
            ndcg50_avg = all_ndcg[50]/float(data_handler.batch_id)
            ndcg100_avg = all_ndcg[100]/float(data_handler.batch_id)
            
            
            print("-> tested samples: " + str(data_handler.batch_id) + " user number: " + str(1 + data_handler.batch_id // pos_size) + ",\n" +
                  " hit@5, 10, 20, 50, 100: " + "{:.4f}".format(hit5_avg) + "," + "{:.4f}".format(hit10_avg) + "," + "{:.4f}".format(hit20_avg) + "," + "{:.4f}".format(hit50_avg) + "," + "{:.4f}".format(hit100_avg) + ",\n" +
                  " mrr@5, 10, 20, 50, 100: " + "{:.4f}".format(mrr5_avg) + "," + "{:.4f}".format(mrr10_avg) + "," + "{:.4f}".format(mrr20_avg) + "," + "{:.4f}".format(mrr50_avg) + "," + "{:.4f}".format(mrr100_avg) + ",\n" +
                  "ndcg@5, 10, 20, 50, 100: " + "{:.4f}".format(ndcg5_avg) + "," + "{:.4f}".format(ndcg10_avg) + "," + "{:.4f}".format(ndcg20_avg) + "," + "{:.4f}".format(ndcg50_avg) + "," + "{:.4f}".format(ndcg100_avg))

    hit1_avg = all_hits[1]/float(data_handler.sample_num)
    hit5_avg = all_hits[5]/float(data_handler.sample_num)
    hit10_avg = all_hits[10]/float(data_handler.sample_num)
    hit20_avg = all_hits[20]/float(data_handler.sample_num)
    hit50_avg = all_hits[50]/float(data_handler.sample_num)
    hit100_avg = all_hits[100]/float(data_handler.sample_num)

    mrr1_avg = all_mrr[1]/float(data_handler.sample_num)
    mrr5_avg = all_mrr[5]/float(data_handler.sample_num)
    mrr10_avg = all_mrr[10]/float(data_handler.sample_num)
    mrr20_avg = all_mrr[20]/float(data_handler.sample_num)
    mrr50_avg = all_mrr[50]/float(data_handler.sample_num)
    mrr100_avg = all_mrr[100]/float(data_handler.sample_num)


    ndcg1_avg = all_ndcg[1]/float(data_handler.sample_num)
    ndcg5_avg = all_ndcg[5]/float(data_handler.sample_num)
    ndcg10_avg = all_ndcg[10]/float(data_handler.sample_num)
    ndcg20_avg = all_ndcg[20]/float(data_handler.sample_num)
    ndcg50_avg = all_ndcg[50]/float(data_handler.sample_num)
    ndcg100_avg = all_ndcg[100]/float(data_handler.sample_num)
    print("\n-> test finished" + ",\n" +
          " hit@5, 10, 20, 50, 100: " + "{:.4f}".format(hit5_avg) + "," + "{:.4f}".format(hit10_avg) + "," + "{:.4f}".format(hit20_avg) + "," + "{:.4f}".format(hit50_avg) + "," + "{:.4f}".format(hit100_avg) + ",\n" +
                  " mrr@5, 10, 20, 50, 100: " + "{:.4f}".format(mrr5_avg) + "," + "{:.4f}".format(mrr10_avg) + "," + "{:.4f}".format(mrr20_avg) + "," + "{:.4f}".format(mrr50_avg) + "," + "{:.4f}".format(mrr100_avg) + ",\n" +
                  "ndcg@5, 10, 20, 50, 100: " + "{:.4f}".format(ndcg5_avg) + "," + "{:.4f}".format(ndcg10_avg) + "," + "{:.4f}".format(ndcg20_avg) + "," + "{:.4f}".format(ndcg50_avg) + "," + "{:.4f}".format(ndcg100_avg))
    
    
    print("Final evaluation metrics per user:")
    for k in [1,5,10,20,50,100]:
        print("Hit@",str(k),':',round(user_hits[k] / user_dim , 6))
        print("MRR@",str(k),':',round(user_mrr[k] / user_dim , 6))
        print("NDCG@",str(k),':',round(user_ndcg[k] / user_dim, 6))

    print("-> test finished.")