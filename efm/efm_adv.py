from __future__ import print_function
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import random
import numpy as np
from sklearn.metrics import ndcg_score
from sklearn.preprocessing import normalize
import argparse
import sys
import matplotlib.pyplot as plt
from tqdm import tqdm
from pathlib import Path
import pickle
sys.path.append("../../data")
from text_processed_dataset import TextProcessedDataset
from yelp_processed_dataset import YelpProcessedDataset
os.environ['CUDA_VISIBLE_DEVICES'] = '2'

def args_process():    # Parse argument
    parser = argparse.ArgumentParser()
    parser.add_argument("--dataset", dest="dataset", type=str, default="electronics",help = 'Name of the dataset')
    parser.add_argument("--adv", dest="adv", type=bool, default = False, help="whether to do adversarial or not")
    parser.add_argument("--adv_method", dest="adv_method", type=str, default = 'FGSM', help="whether to do which adversarial method? Random or FGSM")
    parser.add_argument("--print_every",dest = "print_every",type = int, default = 10, help = 'print every x batches once')
    parser.add_argument("--neg_size", type = int, default = 2, help = 'Negative samples per one positive sample')
    parser.add_argument("--dim", type = int, default = 64, help = 'Hidden Embedding dimensions')
    parser.add_argument("--eps", dest="eps", type=float, default=0.5, help="Error proportion for adversarial training")
    parser.add_argument("--dropout", dest="dropout", type=float, default=0.4, help="Dropout for learning")
    parser.add_argument("--lr", dest="lr", type=float, default=0.001, help="learning rate for training")
    parser.add_argument("--seed", dest="seed", type=int, default=999, help="seed for training")
    parser.add_argument("--epochs", dest="epochs", type=int, default=100, help="training epoch")
    parser.add_argument("--weight_decay", dest="weight_decay", type=float, default=0.1, help="Weight decay")
    parser.add_argument("--batch_size", dest="batch_size", type=int, default=256, help="batch size for training base rec model")
    parser.add_argument("--verbose", type = int, default = 0, help = 'Print extra info')
    parser.add_argument("--data_path",dest = 'data_path', type=str, default ='../data/final-obj/Electronics_dataset_obj.pickle',help = "Path to the dataset for loading")
    parser.add_argument("--rec_k", dest="rec_k", type=int, default=20, help="length of rec list")
    parser.add_argument("--exp_k", dest="exp_k", type=int, default=5, help="length of expl list")
    parser.add_argument("--alpha", dest="alpha", type=float, default=0.5, help="ratio for the personalized recommendation")
    parser.add_argument("--model_path", dest="model_path", type=str, default="./logs/",help = 'path to vanilla model')
    args = parser.parse_args()
    return args

def plot_metrics(metrics, metric_name = 'Loss',dataset = "Electronics",adv = False, adv_method = 'fgsm',eps = 0.5, multi = False,names = None,model_name = 'EFM'):
    epochs = list(range(1 , 1 + len(metrics)))
    image_name = model_name+"-plots/" + dataset + "_" + metric_name
    if adv:
        image_name += '_ADV'+"_"+str(adv_method)+"_"+str(eps)
    dirname = os.path.dirname(os.path.abspath(image_name))
    os.makedirs(dirname, exist_ok=True)
    plt.figure(figsize = (12,8))
    plt.title(model_name + "-" + dataset + "-" + metric_name + ' vs Epochs')
    
    if multi:
        
        for name,metric in zip(names,metrics):
            epochs = list(range(1 , 1 + len(metric)))
            plt.plot(epochs, metric, label = name)
    else:
        plt.plot(epochs, metrics)
    
    
    plt.xlabel("Epochs")
    plt.ylabel(metric_name)
    if multi:
        plt.legend()
    
    plt.savefig(image_name + '.png') 



def eval_model(A,X,Y, test_data,rec_k=20,exp_k = 10,alpha = 0.5, N = 5.0):
    
    Ks = [5,10,20,50,100]
    max_K = max(Ks)
    top_k = {}
    precisions = {5:[],10:[],20:[],50:[],100:[]}
    recalls = {5:[],10:[],20:[],50:[],100:[]}
    ndcgs= {5:[], 10:[], 20: [], 50: [], 100:[]}
    top_k_items = []
    for row in test_data:
        user = row[0]
        items = row[1]
        gt_labels = row[2]
        users = [user for _ in items]
        scores = []
        
        user_care = X[user, :]
        idx = np.argpartition(user_care, -exp_k)
        idx = idx[-exp_k:]
        
        for index in list(zip(users,items)):
            u,i = index
            tmp = X[u, idx].dot(Y[i, idx].T) / (exp_k * N)
            score = tmp * alpha + (1 - alpha) * A[u, i]
            scores.append(score)
        
        scores = np.array(scores)
        triples = [(item,ground,score) for item,ground,score in list(zip(items,gt_labels,scores))]
        triples.sort(key = lambda x: x[2],reverse= True)
        final_triples = triples[:max_K]
        
        top_k_items.append([item for item,_,_ in final_triples])
        top_k[user] = final_triples
    
    for row in test_data:
        user = row[0]
        items = row[1]
        triple = top_k[user]
        for top in Ks:
            curr_triple = triple[:top]
            items_recommended,gt_k,score_k = list(zip(*curr_triple))
            items_relevant = [item for i,(item,score,label) in enumerate(zip(items_recommended, score_k,gt_k)) if label == 1]

            common = set(items) & set(items_relevant)
            common_size = len(common)
            recalls[top].append(common_size / len(items))
            precisions[top].append(common_size / min([top, len(items)]))
            ndcg = ndcg_score([gt_labels], [scores], k=top)
            ndcgs[top].append(ndcg)

    returns = ()
    for top in Ks:
        recall = np.mean(recalls[top])
        precision = np.mean(precisions[top])
        
        if precision + recall != 0:
            f1 = 2 * recall * precision / (precision + recall)
        
        else:
            f1 = 0.0
        
        precision = round(precision,6)
        recall = round(recall,6)
        f1 = round(f1,6)
        ndcg = round(np.mean(ndcgs[top]),100)
        if top == rec_k:
            returns = (ndcg, recall, precision, f1)
        print("\t\t", 'NDCG@',top,":",ndcg,end = '\t\t')
        print("Precision@",top,":",precision,'Recall@',top,":", recall," F1@",top,":",f1)
        
    return returns

def adv_training(A, X, Y, weights,r, r_, lambda_x, lambda_y, lambda_u, lambda_h, lambda_v, T, alpha,args,test_data):
    m = X.shape[0]
    p = X.shape[1]
    n = Y.shape[0]
    U1 = weights[0]
    U2 = weights[1]
    V = weights[2]
    H1 = weights[3]
    H2 = weights[4]
    
    U1noise = np.zeros((m,r))
    U2noise = np.zeros((n,r))
    Vnoise = np.zeros((p,r))
    eps = float(args.eps)
    
    t = 0
    top_k = int(args.rec_k)
    ndcgs,precisions, recalls,f1s = [],[],[],[]
    losses = {'1':[],'2':[],'3':[],'reg':[],'all':[]}
    for t in tqdm(range(1, T + 1)):
        _U1 = np.zeros((m,r))
        _U2 = np.zeros((n,r))
        _V = np.zeros((p,r))
        

        E = 0
        
        err1 = 0
        err2 = 0 
        err3 = 0
        row1, col1 = np.where(A > 0)
        row2, col2 = np.where(X > 0)
        row3, col3 = np.where(Y > 0)
        for i,j in tqdm(zip(row1,col1)):
                            
            e1_ij = - A[i,j] + (U1[i, :] + U1noise[i,:]).dot(U2.T[:, j] + U2noise.T[:,j]) + H1[i, :].dot(H2.T[:, j])
            E += pow(e1_ij, 2)
            for k in range(r):
                _U1[i, k] += alpha *  2 * e1_ij * (U2[j,k] + U2noise[j,k])
                _U2[j, k] += alpha *  2 * e1_ij * (U1[i,k] + U1noise[i,k])
            
            
            

        err1 = E
        losses['1'].append(err1)
        for i,j in tqdm(zip(row2,col2)):
                        
                
            e2_ij = - X[i, j] + (U1[i, :] + U1noise[i,:]).dot(V.T[:, j] + Vnoise.T[:,j])
            E += pow(e2_ij, 2)
            for k in range(r):
                _U1[i, k] += alpha * (2 * e2_ij * (V[j, k] + Vnoise[j,k]))
                _V[j, k]  += alpha * (2 * e2_ij * (U1[i, k] + U1noise[i,k]))
        
       
        err2 = E - err1
        losses['2'].append(err2)
        for i,j in tqdm(zip(row3,col3)):
                
            e3_ij = - Y[i, j] + (U2[i, :] + U2noise[i,:]).dot(V.T[:, j] + Vnoise.T[:,j])
            E += pow(e3_ij, 2)
            for k in range(r):
                _U2[i, k] += alpha * (2 * e3_ij * (V[j, k] + Vnoise[j,k]))
                _V[j, k] += alpha * (2 * e3_ij * (U2[i, k] + U2noise[i,k]))
        
        err3 = E - (err1 + err2)
                          
        
        losses['3'].append(err3)        
        losses['all'].append(E)
        
        
        U1noise += _U1
        U2noise += _U2
        Vnoise += _V
        
        U1noise = normalize(U1noise,norm = 'l2', axis = 1)
        U2noise = normalize(U2noise,norm = 'l2', axis = 1)
        Vnoise = normalize(Vnoise,norm = 'l2', axis = 1)
        
        U1noise *= eps
        U2noise *= eps
        Vnoise *= eps
        
        print("U1 noise finally:",U1noise)
        print("U2 noise finally: ",U2noise)
        print("V noise finally: ",Vnoise)
        
        print("Norm of the U1 noise:",np.linalg.norm(U1noise))
        print("Norm of the U2 noise:",np.linalg.norm(U2noise))
        print("Norm of the V noise:",np.linalg.norm(Vnoise))
        
        
        print("\nLoss after ",t, ' epochs: ', ' Loss 1: ',round(err1,6), ' Loss 2:',round(err2,6)," Loss 3: ",round(err3,6),' Total Loss: ', round(E,6))
        if t % args.print_every == 0 or t == 1 or t == T:
            X_ = (U1 + U1noise).dot(V.T + Vnoise.T)
            Y_ = (U2 + U2noise).dot(V.T + Vnoise.T)
            A_ = (U1 + U1noise).dot(U2.T + U2noise.T) + H1.dot(H2.T)
            nd,re,pr,f1 = eval_model(A_,X_,Y_, test_data,top_k,args.exp_k,args.alpha)
            ndcgs.append(nd)
            recalls.append(re)
            precisions.append(pr)
            f1s.append(f1)
#             sys.exit()

    
    
    plot_metrics(metrics = [losses['1'],losses['all']], metric_name = 'Loss-main',dataset = args.dataset,adv = args.adv, adv_method = args.adv_method,eps = args.eps, multi = True,names = ['Loss User-Item','Loss Total'],model_name = 'EFM')
    plot_metrics(metrics = [losses['2'],losses['3']],metric_name = 'Loss-feature',dataset = args.dataset,adv = args.adv, adv_method = args.adv_method,eps = args.eps, multi = True, names = ['Loss User-Feature','Loss Item-Feature'],model_name = 'EFM')
    plot_metrics(ndcgs,metric_name = 'NDCG@'+str(top_k), dataset = args.dataset, adv=args.adv,adv_method = args.adv_method,eps=str(args.eps),model_name='EFM')
    plot_metrics(precisions,metric_name = 'Precision@'+str(top_k), dataset = args.dataset, adv=args.adv,adv_method = args.adv_method,eps=str(args.eps),model_name='EFM')
    plot_metrics(recalls,metric_name = 'Recall@'+str(top_k),  dataset = args.dataset, adv=args.adv,adv_method = args.adv_method,eps=str(args.eps),model_name='EFM')
    plot_metrics(f1s,metric_name = 'F1@'+str(top_k),  dataset = args.dataset, adv=args.adv,adv_method = args.adv_method,eps=str(args.eps),model_name='EFM')

    return weights + [U1noise, U2noise, Vnoise]
              
def main():
    args = args_process()
    print("Args:",args)
    with open(args.data_path, 'rb') as handle:
        rec_dataset = pickle.load(handle)

    print("DATASET:",args.dataset.upper())
    rec_dataset.printDetails()

    user_dim = rec_dataset.user_num
    item_dim = rec_dataset.item_num
    attribute_dim = rec_dataset.feature_num

    pos_size = 6 # change based on what test data you use depending on number of positive samples per user
    N = 5 # maximum score
    hidden_dim = int(args.dim)
    
    seed = int(args.seed)
    adv = bool(args.adv)
    adv_method = str(args.adv_method)
    eps = float(args.eps)
    rec_k = int(args.rec_k)
    exp_k = int(args.exp_k)
    
    random.seed(seed)
    np.random.seed(seed)
    with open(args.model_path, 'rb') as handle:
        weights = pickle.load(handle)
        U1,U2,V,H1,H2 = weights[0],weights[1],weights[2], weights[3], weights[4]
    
    name = 'EFM_'+str(args.dataset).upper()
    name += '_' + adv_method.upper() + "_" + str(eps)
    name += '.pkl'
    
    user_item_matrix = np.zeros((user_dim, item_dim))
    train_data = rec_dataset.training_data
    test_data = rec_dataset.test_data

    # make the A matrix!
    for row in train_data:
            
        user = row[0]
        item = row[1]
        label = row[2]
        user_item_matrix[user,item] = label
    
    print("Initial metrics:")
    X_ = U1.dot(V.T)
    Y_ = U2.dot(V.T)
    A_ = U1.dot(U2.T) + H1.dot(H2.T)
    
    eval_model(A_,X_,Y_, test_data,rec_k,exp_k, args.alpha)
    
    if adv_method.upper() == 'RANDOM':
        
        
        U1noise = np.random.normal(loc = 0, scale = 1, size = U1.shape)
        U2noise = np.random.normal(loc = 0, scale = 1, size = U2.shape)
        Vnoise = np.random.normal(loc = 0, scale = 1, size = V.shape)
        
        U1noise = normalize(U1noise,norm = 'l2', axis = 1)
        U2noise = normalize(U2noise,norm = 'l2', axis = 1)
        Vnoise = normalize(Vnoise,norm = 'l2', axis = 1)
        
        
        U1noise *= eps
        U2noise *= eps
        Vnoise *= eps
        
        print("Norm of the U1 noise:",np.linalg.norm(U1noise,axis = 1))
        print("Norm of the U2 noise:",np.linalg.norm(U2noise,axis = 1))
        print("Norm of the V noise:",np.linalg.norm(Vnoise,axis = 1))

        
        
        Xnoise_ = (U1 + U1noise).dot(V.T + Vnoise.T)
        Ynoise_ = (U2 + U2noise).dot(V.T + Vnoise.T)
        Anoise_ = (U1 + U1noise).dot(U2.T + U2noise.T) + (H1).dot(H2.T)
        print("Adding noise gives us:")
        
        eval_model(Anoise_,Xnoise_,Ynoise_,test_data,rec_k,exp_k, args.alpha)
        
        params = weights + [U1noise, U2noise, Vnoise]
        with open("base-models/" + name,'wb') as outp:
            pickle.dump(params, outp, pickle.HIGHEST_PROTOCOL)
        
        sys.exit(0)
    
    # FGSM has to be done
    
    params = adv_training(user_item_matrix, rec_dataset.user_feature_matrix, rec_dataset.item_feature_matrix, weights, hidden_dim, hidden_dim,args.weight_decay,args.weight_decay,args.weight_decay ,args.weight_decay ,args.weight_decay, int(args.epochs), float(args.lr),args,rec_dataset.test_data)
    with open("base-models/" + name,'wb') as outp:
        pickle.dump(params, outp, pickle.HIGHEST_PROTOCOL)
    
        
if __name__ == '__main__':
    main()